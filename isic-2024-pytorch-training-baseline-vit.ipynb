{"cells":[{"cell_type":"markdown","metadata":{},"source":["# ISIC 2024 - Skin Cancer Detection: Pytorch Model w/ Image + Metadata (5 Folds)"]},{"cell_type":"markdown","metadata":{},"source":["Inspired by [motono0223](https://www.kaggle.com/code/motono0223/isic-pytorch-training-baseline-eva02/notebook#Run-Training) \n","\n","Idea:\n","* Use 1:20 benign vs malignant training data\n","* Feature engineer and append snippet of data to images\n","* Data augment images for diversity\n","* Train Vision Transformer and simple PyTorch model\n","* Save model base on better validation AUROC\n","\n","Notebooks:\n","* Training notebook (current)\n","* [Inference notebook](https://www.kaggle.com/code/qiaoyingzhang/isic-2024-pytorch-inference-swin-vit/notebook)"]},{"cell_type":"markdown","metadata":{},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install torcheval"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import gc\n","import cv2\n","import copy\n","import time\n","import random\n","import glob\n","import h5py\n","import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","from io import BytesIO\n","\n","# PyTorch Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torcheval.metrics.functional import binary_auroc\n","\n","# Utils\n","import joblib\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","# Sklearn Imports\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.model_selection import StratifiedGroupKFold\n","\n","# For Image Models\n","import timm\n","\n","# Albumentations for augmentations\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","# For colored terminal text\n","from colorama import Fore, Back, Style\n","b_ = Fore.BLUE\n","sr_ = Style.RESET_ALL\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# For descriptive error messages\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""]},{"cell_type":"markdown","metadata":{},"source":["# Initialize Environment & Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["CONFIG = {\n","    \"seed\": 2024,\n","    \"epochs\": 50,\n","    \"img_size\": 224,\n","    \"model_name\": 'vit_base_patch16_224',\n","    \"train_batch_size\": 32,\n","    \"valid_batch_size\": 64,\n","    \"learning_rate\": 1e-5,\n","    \"scheduler\": 'CosineAnnealingLR',\n","    \"min_lr\": 1e-10,\n","    \"T_max\": 500,\n","    \"weight_decay\": 1e-6,\n","#     \"fold\" : 1,\n","    \"n_fold\": 5,\n","    \"n_accumulate\": 1,\n","    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n","}\n","\n","# Set seed for reproducibility\n","def seed_everything(seed):\n","    '''Sets the seed of the entire notebook so results are the same every time we run.\n","    This is for REPRODUCIBILITY.'''\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    \n","seed_everything(CONFIG['seed'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ROOT_DIR = \"/kaggle/input/isic-2024-challenge\"\n","HDF_FILE = f\"{ROOT_DIR}/train-image.hdf5\""]},{"cell_type":"markdown","metadata":{},"source":["# Data Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.read_csv(f\"{ROOT_DIR}/train-metadata.csv\")\n","\n","print(\"       df.shape, # of positive cases, # of patients\")\n","print(\"original>\", df.shape, df.target.sum(), df[\"patient_id\"].unique().shape)\n","\n","df_positive = df[df[\"target\"] == 1].reset_index(drop=True)\n","df_negative = df[df[\"target\"] == 0].reset_index(drop=True)\n","\n","# Data ratio -> positive:negative = 1:25\n","df = pd.concat([df_positive, df_negative.iloc[:df_positive.shape[0]*20, :]])  \n","print(\"filtered>\", df.shape, df.target.sum(), df[\"patient_id\"].unique().shape)\n","\n","df = df.reset_index(drop=True)\n","print(\"df.shape, # of positive cases, # of patients\")\n","print(\"original>\", df.shape, df.target.sum(), df[\"patient_id\"].unique().shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Feature engineering\n","df['lesion_size_ratio'] = df['tbp_lv_minorAxisMM'] / df['clin_size_long_diam_mm']\n","df['color_uniformity'] = df['tbp_lv_color_std_mean'] / df['tbp_lv_radial_color_std_max']\n","df['3d_position_distance'] = np.sqrt(df['tbp_lv_x'] ** 2 + df['tbp_lv_y'] ** 2 + df['tbp_lv_z'] ** 2) \n","# List of numerical features to be scaled\n","num_feat = ['age_approx', 'lesion_size_ratio', 'color_uniformity', \n","            'tbp_lv_Lext', 'tbp_lv_eccentricity', '3d_position_distance']\n","\n","# Replace infinite values with NaN\n","df[num_feat] = df[num_feat].replace([np.inf, -np.inf], np.nan)\n","\n","# Handle missing values (if any) by filling them with the mean of the column\n","df[num_feat] = df[num_feat].fillna(df[num_feat].mean())\n","\n","# Scale numerical features\n","scaler = StandardScaler()\n","df[num_feat] = scaler.fit_transform(df[num_feat])\n","\n","print(\"Feature engineering and scaling complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["CONFIG['T_max'] = df.shape[0] * (CONFIG['n_fold']-1) * CONFIG['epochs'] \\\n","// CONFIG['train_batch_size'] // CONFIG['n_fold']\n","\n","print(CONFIG['T_max'])"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Manipulation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Dataset\n","class ISICDataset(Dataset):\n","    def __init__(self, dataframe, feat, file_path, transforms=None, is_training=True):\n","        self.df = dataframe\n","        self.file_path = h5py.File(file_path, mode=\"r\")\n","        self.transforms = transforms\n","        self.is_training = is_training\n","        self.df_positive = self.df[self.df['target'] == 1].reset_index()\n","        self.df_negative = self.df[self.df['target'] == 0].reset_index()\n","        self.isic_ids_positive = self.df_positive['isic_id'].values\n","        self.isic_ids_negative = self.df_negative['isic_id'].values\n","        self.targets_positive = self.df_positive['target'].values\n","        self.targets_negative = self.df_negative['target'].values\n","        self.metadata = self.df[feat].values\n","\n","    def __len__(self):\n","        return len(self.df_positive) * 2 if self.is_training else len(self.df)\n","\n","    def __getitem__(self, idx):\n","        if self.is_training:\n","            is_positive = random.random() >= 0.5\n","            df_subset = self.df_positive if is_positive else self.df_negative\n","            isic_ids = self.isic_ids_positive if is_positive else self.isic_ids_negative\n","            targets = self.targets_positive if is_positive else self.targets_negative\n","            idx = idx % len(df_subset)\n","            target = targets[idx]\n","            isic_id = isic_ids[idx]\n","        else:\n","            row = self.df.iloc[idx]\n","            target = row['target']\n","            isic_id = row['isic_id']\n","        \n","        metadata = self.metadata[idx]\n","        \n","        image = np.array(Image.open(BytesIO(self.file_path[isic_id][()])))\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        if self.transforms:\n","            image = self.transforms(image=image)[\"image\"]\n","        \n","        return {'image': image, 'target': target, 'metadata': metadata}"]},{"cell_type":"markdown","metadata":{},"source":["# Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Modeling - hybrid model w/ CNN + Metadata\n","class CustomISICModel(nn.Module):\n","    def __init__(self, model_name, num_classes=1, pretrained=True):\n","        super(CustomISICModel, self).__init__()\n","        self.image_model = timm.create_model(model_name, pretrained=pretrained)\n","        self.image_out_features = self.image_model.get_classifier().in_features\n","        self.image_model.reset_classifier(0)  # Remove the original classifier\n","\n","        # Metadata part\n","        metadata_input_features = 6\n","        metadata_output_features = 128\n","\n","        self.metadata_fc = nn.Sequential(\n","            nn.Linear(metadata_input_features, 128),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(128, 256),\n","            nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(256, metadata_output_features),\n","            nn.BatchNorm1d(metadata_output_features),\n","            nn.ReLU()\n","        )\n","\n","        # Combine features from image model and metadata\n","        combined_features = self.image_out_features + metadata_output_features\n","        self.final_fc = nn.Sequential(\n","            nn.Linear(combined_features, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(512, num_classes),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, image, metadata):\n","        image_features = self.image_model(image)\n","        metadata_features = self.metadata_fc(metadata)\n","        combined_features = torch.cat((image_features, metadata_features), dim=1)\n","        output = self.final_fc(combined_features)\n","        \n","        return output\n","\n","# Check model    \n","model = CustomISICModel(CONFIG['model_name'], pretrained=True)\n","\n","model.to(CONFIG['device'])"]},{"cell_type":"markdown","metadata":{},"source":["# Data Augmentation & Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define image transformer\n","data_transforms = {\n","    'train': A.Compose([\n","        A.RandomRotate90(p=0.5),\n","        A.Flip(p=0.5),\n","        A.Transpose(p=0.5),\n","        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=45, p=0.5),\n","        A.OneOf([\n","            A.HueSaturationValue(p=0.5),\n","            A.RandomBrightnessContrast(p=0.5),\n","        ], p=0.5),\n","        A.OneOf([\n","            A.GaussNoise(p=0.5),\n","            A.GaussianBlur(p=0.5),\n","            A.MotionBlur(p=0.5),\n","        ], p=0.5),\n","        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n","        A.Normalize(\n","            mean=[0.4815, 0.4578, 0.4082], \n","            std=[0.2686, 0.2613, 0.2758], \n","            max_pixel_value=255.0),\n","        ToTensorV2(),\n","    ]),\n","    \n","    'valid': A.Compose([\n","        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n","        A.Normalize(\n","            mean=[0.4815, 0.4578, 0.4082], \n","            std=[0.2686, 0.2613, 0.2758], \n","            max_pixel_value=255.0),\n","        ToTensorV2(),\n","    ])\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Loss function\n","def criterion(outputs, targets):\n","    return nn.BCELoss()(outputs, targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Running training and validation\n","def prepare_loaders(df, fold):\n","    train_df = df[df['fold'] != fold].reset_index(drop=True)\n","    valid_df = df[df['fold'] == fold].reset_index(drop=True)\n","\n","    train_dataset = ISICDataset(train_df, feat=num_feat, file_path=HDF_FILE, \n","                                transforms=data_transforms['train'], is_training=True)\n","    valid_dataset = ISICDataset(valid_df, feat=num_feat, file_path=HDF_FILE, \n","                                transforms=data_transforms['valid'], is_training=False)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], shuffle=True, \n","                              num_workers=4, pin_memory=True)\n","    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], shuffle=False, \n","                              num_workers=4, pin_memory=True)\n","    \n","    return train_loader, valid_loader"]},{"cell_type":"markdown","metadata":{},"source":["# Training & Validation Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Main training function\n","def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_epoch_auroc = 0\n","    best_epoch_loss = 1\n","    history = defaultdict(list)\n","    \n","    for epoch in range(1, num_epochs + 1):\n","        gc.collect()\n","        train_epoch_loss, train_epoch_auroc = train_one_epoch(model, optimizer, \n","                                                              scheduler, dataloader=train_loader, \n","                                                              device=device, epoch=epoch)\n","        \n","        val_epoch_loss, val_epoch_auroc = valid_one_epoch(model, valid_loader, device=device, epoch=epoch)\n","        \n","        history['Train Loss'].append(train_epoch_loss)\n","        history['Train AUROC'].append(train_epoch_auroc)\n","        history['Valid Loss'].append(val_epoch_loss)\n","        history['Valid AUROC'].append(val_epoch_auroc)\n","        \n","        # deep copy the model (balance auroc and loss accuracy)\n","        if (best_epoch_auroc <= val_epoch_auroc) & (best_epoch_loss - val_epoch_loss >= -0.05):\n","            print(f\"{b_}Validation AUROC Improved ({best_epoch_auroc} ---> {val_epoch_auroc})\")\n","            best_epoch_auroc = val_epoch_auroc\n","            best_epoch_loss = val_epoch_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            \n","            # Save a model file from the current directory\n","            PATH = f\"best_AUROC_model_fold{fold}.bin\"\n","            torch.save(model.state_dict(), PATH)\n","            print(f\"Model Saved -- epoch: {epoch:.0f}, AUROC: {val_epoch_auroc:.4f}, Loss: {val_epoch_loss:.4f}{sr_}\")\n","\n","    print('Best val AUROC: {:4f}'.format(best_epoch_auroc))\n","    \n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    \n","    return model, history"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Training\n","def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","    model.train()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    running_auroc  = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:\n","        images = data['image'].to(device, dtype=torch.float)\n","        metadata = data['metadata'].to(device, dtype=torch.float)\n","        targets = data['target'].to(device, dtype=torch.float)\n","        \n","        batch_size = images.size(0)\n","        \n","        outputs = model(images, metadata).squeeze()\n","        loss = criterion(outputs, targets)\n","        loss = loss / CONFIG['n_accumulate']\n","            \n","        loss.backward()\n","    \n","        if (step + 1) % CONFIG['n_accumulate'] == 0:\n","            optimizer.step()\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            if scheduler is not None:\n","                scheduler.step()\n","                \n","        auroc = binary_auroc(input=outputs, target=targets).item()\n","        \n","        running_loss += (loss.item() * batch_size)\n","        running_auroc  += (auroc * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        epoch_auroc  = running_auroc  / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, Train_AUROC=epoch_auroc, \n","                        LR=optimizer.param_groups[0]['lr'])\n","        \n","    gc.collect()\n","    \n","    return epoch_loss, epoch_auroc "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Validation\n","\n","@torch.no_grad()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    running_auroc  = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:\n","        images = data['image'].to(device, dtype=torch.float)\n","        metadata = data['metadata'].to(device, dtype=torch.float)\n","        targets = data['target'].to(device, dtype=torch.float)\n","        \n","        batch_size = images.size(0)\n","        \n","        outputs = model(images, metadata).squeeze()\n","        loss = criterion(outputs, targets)\n","        \n","        auroc = binary_auroc(input=outputs, target=targets).item()\n","        \n","        running_loss += (loss.item() * batch_size)\n","        running_auroc  += (auroc * batch_size)\n","        dataset_size += batch_size\n","\n","        epoch_loss = running_loss / dataset_size\n","        epoch_auroc  = running_auroc  / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss, Valid_AUROC=epoch_auroc)\n","        \n","    gc.collect()\n","    \n","    return epoch_loss, epoch_auroc "]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot Loss and AUROC Curves\n","def plot_metrics(history):\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n","\n","    ax1.plot(history['Train Loss'], label='Train Loss')\n","    ax1.plot(history['Valid Loss'], label='Valid Loss')\n","    ax1.set_title('Loss Curves')\n","    ax1.legend()\n","\n","    ax2.plot(history['Train AUROC'], label='Train AUROC')\n","    ax2.plot(history['Valid AUROC'], label='Valid AUROC')\n","    ax2.set_title('AUROC Curves')\n","    ax2.legend()\n","\n","    plt.show()\n","\n","# plot_metrics(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Preparing stratified k-fold\n","skf = StratifiedGroupKFold(n_splits=CONFIG['n_fold'])\n","\n","for fold, (train_idx, val_idx) in enumerate(skf.split(X=df, y=df.target, groups=df.patient_id)):\n","    df.loc[val_idx, 'fold'] = fold"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Get best model for multiple folds\n","for fold in range(CONFIG['n_fold']):\n","    print(f'{b_}Training Fold {fold}')\n","    print(f'------------------------------{sr_}')\n","    torch.cuda.empty_cache()\n","    \n","    # Setup model\n","    model = CustomISICModel(CONFIG['model_name'], pretrained=True)\n","    model.to(CONFIG['device'])\n","    \n","    # Optimizer & Scheduler\n","    optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], \n","                           weight_decay=CONFIG['weight_decay'])\n","\n","    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n","        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['T_max'], \n","                                                   eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n","        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CONFIG['T_0'], \n","                                                             eta_min=CONFIG['min_lr'])\n","        \n","    # Prepare Dataloaders\n","    train_loader, valid_loader = prepare_loaders(df, fold=fold)\n","    \n","    # Run training\n","    model, history = run_training(model, optimizer, scheduler,\n","                                  CONFIG['device'], CONFIG['epochs'], fold)\n","    \n","    # Metric logs\n","    plot_metrics(history)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":9094797,"sourceId":63056,"sourceType":"competition"},{"datasetId":5615162,"sourceId":9277641,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
