{"cells":[{"cell_type":"markdown","metadata":{},"source":["# ISIC 2024 - Skin Cancer Detection: Pytorch Model w/ Image + Metadata Inference"]},{"cell_type":"markdown","metadata":{},"source":["Inspired by [motono0223](https://www.kaggle.com/code/motono0223/isic-pytorch-baseline-pseudo-labeling-eva02#Create-Model) and [Jiadi Wang](https://www.kaggle.com/code/hugowjd/isic-2024-pytorch-inference-effnet-b3#Create-Model)\n","\n","Idea:\n","* Feature engineer and append snippet of data to images\n","* Data augment images for diversity\n","* Inference with multiple folds\n","\n","Notebooks:\n","* [Training notebook](https://www.kaggle.com/code/qiaoyingzhang/isic-2024-pytorch-training-baseline-swin/notebook?scriptVersionId=191356799) -- version 16\n","* Inference notebook (current)\n","\n","Best models (manually selected from training notebook) are uploaded in [dataset](https://www.kaggle.com/datasets/qiaoyingzhang/isic-2024-swin-pytorch-best-models)\n","* Fold 0 best model from [version 9](https://www.kaggle.com/code/qiaoyingzhang/isic-2024-pytorch-training-baseline-swin?scriptVersionId=191338975) (AUROC0.5181_Loss0.2202_epoch41_fold0.bin)\n","* Fold 1 best model from [version 8](https://www.kaggle.com/code/qiaoyingzhang/isic-2024-pytorch-training-baseline-swin?scriptVersionId=191338963) (AUROC0.5184_Loss0.3117_epoch31_fold1.bin)\n","* Fold 2 best model from [version 10](https://www.kaggle.com/code/qiaoyingzhang/isic-2024-pytorch-training-baseline-swin?scriptVersionId=191342208) (AUROC0.5173_Loss0.2800_epoch41_fold2.bin)\n","* Fold 3 best model from [version 11](https://www.kaggle.com/code/qiaoyingzhang/isic-2024-pytorch-training-baseline-swin?scriptVersionId=191342225) (AUROC0.5175_Loss0.3176_epoch6_fold3.bin)\n","* Fold 4 best model from [version 12](https://www.kaggle.com/code/qiaoyingzhang/isic-2024-pytorch-training-baseline-swin?scriptVersionId=191346483) (AUROC0.5177_Loss0.2280_epoch49_fold4.bin)"]},{"cell_type":"markdown","metadata":{},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-01T13:26:38.516478Z","iopub.status.busy":"2024-09-01T13:26:38.516199Z","iopub.status.idle":"2024-09-01T13:26:46.683475Z","shell.execute_reply":"2024-09-01T13:26:46.682675Z","shell.execute_reply.started":"2024-09-01T13:26:38.516454Z"},"trusted":true},"outputs":[],"source":["import os\n","import gc\n","import cv2\n","import copy\n","import time\n","import random\n","import glob\n","import h5py\n","import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","from io import BytesIO\n","\n","# PyTorch Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","\n","# Utils\n","import joblib\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","# Sklearn Imports\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.model_selection import StratifiedGroupKFold\n","\n","# For Image Models\n","import timm\n","\n","# Albumentations for augmentations\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","# For colored terminal text\n","from colorama import Fore, Back, Style\n","b_ = Fore.BLUE\n","sr_ = Style.RESET_ALL\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# For descriptive error messages\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""]},{"cell_type":"markdown","metadata":{},"source":["# Initialize Environment & Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T13:26:46.685368Z","iopub.status.busy":"2024-09-01T13:26:46.684886Z","iopub.status.idle":"2024-09-01T13:26:46.723215Z","shell.execute_reply":"2024-09-01T13:26:46.722538Z","shell.execute_reply.started":"2024-09-01T13:26:46.685343Z"},"trusted":true},"outputs":[],"source":["CONFIG = {\n","    \"seed\": 2024,\n","    \"img_size\": 224,\n","    \"model_name\": 'swin_large_patch4_window7_224',\n","    \"valid_batch_size\": 64,\n","    \"multiple_folds\": True,\n","    \"selected\": True,\n","    \"n_fold\": 5,\n","    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n","}\n","\n","# Set seed for reproducibility\n","def seed_everything(seed):\n","    '''Sets the seed of the entire notebook so results are the same every time we run.\n","    This is for REPRODUCIBILITY.'''\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    \n","seed_everything(CONFIG['seed'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T13:26:46.724733Z","iopub.status.busy":"2024-09-01T13:26:46.724458Z","iopub.status.idle":"2024-09-01T13:26:46.734792Z","shell.execute_reply":"2024-09-01T13:26:46.734072Z","shell.execute_reply.started":"2024-09-01T13:26:46.724710Z"},"trusted":true},"outputs":[],"source":["ROOT_DIR = \"/kaggle/input/isic-2024-challenge\"\n","TEST_CSV = f'{ROOT_DIR}/test-metadata.csv'\n","TEST_HDF = f'{ROOT_DIR}/test-image.hdf5'\n","SAMPLE = f'{ROOT_DIR}/sample_submission.csv'"]},{"cell_type":"markdown","metadata":{},"source":["# Data Setup (Psuedo Labeling)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T13:20:34.530729Z","iopub.status.busy":"2024-09-01T13:20:34.530460Z","iopub.status.idle":"2024-09-01T13:20:34.558654Z","shell.execute_reply":"2024-09-01T13:20:34.557791Z","shell.execute_reply.started":"2024-09-01T13:20:34.530707Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(TEST_CSV)\n","df['target'] = 0 # dummy"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Feature engineering\n","df['lesion_size_ratio'] = df['tbp_lv_minorAxisMM'] / df['clin_size_long_diam_mm']\n","df['color_uniformity'] = df['tbp_lv_color_std_mean'] / df['tbp_lv_radial_color_std_max']\n","df['3d_position_distance'] = np.sqrt(df['tbp_lv_x'] ** 2 + df['tbp_lv_y'] ** 2 + df['tbp_lv_z'] ** 2) \n","# List of numerical features to be scaled\n","num_feat = ['age_approx', 'lesion_size_ratio', 'color_uniformity', \n","            'tbp_lv_Lext', 'tbp_lv_eccentricity', '3d_position_distance']\n","\n","# Replace infinite values with NaN\n","df[num_feat] = df[num_feat].replace([np.inf, -np.inf], np.nan)\n","\n","# Handle missing values (if any) by filling them with the mean of the column\n","df[num_feat] = df[num_feat].fillna(df[num_feat].mean())\n","\n","# Scale numerical features\n","scaler = StandardScaler()\n","df[num_feat] = scaler.fit_transform(df[num_feat])\n","\n","print(\"Feature engineering and scaling complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Sanity check\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Sample submission\n","df_sub = pd.read_csv(SAMPLE)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Manipulation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T13:26:46.737684Z","iopub.status.busy":"2024-09-01T13:26:46.736852Z","iopub.status.idle":"2024-09-01T13:26:46.748320Z","shell.execute_reply":"2024-09-01T13:26:46.747440Z","shell.execute_reply.started":"2024-09-01T13:26:46.737627Z"},"trusted":true},"outputs":[],"source":["# Dataset\n","class ISICDataset(Dataset):\n","    def __init__(self, dataframe, feat, file_path, transforms=None):\n","        self.df = dataframe\n","        self.file_path = h5py.File(file_path, mode=\"r\")\n","        self.transforms = transforms\n","        self.metadata = self.df[feat].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        target = row['target']\n","        isic_id = row['isic_id']\n","        \n","        metadata = self.metadata[idx]\n","\n","        image = np.array(Image.open(BytesIO(self.file_path[isic_id][()])))\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        if self.transforms:\n","            image = self.transforms(image=image)[\"image\"]\n","        \n","        return {'image': image, 'target': target, 'metadata': metadata}"]},{"cell_type":"markdown","metadata":{},"source":["# Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T13:26:47.440155Z","iopub.status.busy":"2024-09-01T13:26:47.439816Z","iopub.status.idle":"2024-09-01T13:26:47.453117Z","shell.execute_reply":"2024-09-01T13:26:47.452055Z","shell.execute_reply.started":"2024-09-01T13:26:47.440130Z"},"trusted":true},"outputs":[],"source":["class Swish(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, i):\n","        result = i * nn.Sigmoid()(i)\n","        ctx.save_for_backward(i)\n","        return result\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        i = ctx.saved_variables[0]\n","        sigmoid_i = nn.Sigmoid()(i)\n","        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n","\n","class Swish_Module(nn.Module):\n","    def forward(self, x):\n","        return Swish.apply(x)\n","        \n","\n","class CustomISICModel(nn.Module):\n","    def __init__(self, model_name, num_classes=1, pretrained=True, checkpoint_path=None):\n","        super(CustomISICModel, self).__init__()\n","        self.image_model = timm.create_model(model_name, pretrained=pretrained, \n","                                             chekpoint_path=checkpoint_path)\n","        self.image_out_features = self.image_model.get_classifier().in_features\n","        self.image_model.reset_classifier(0)  # Remove the original classifier\\\n","        \n","\n","        # Metadata part\n","        metadata_input_features = 6\n","        metadata_output_features = 128\n","\n","        self.metadata_fc = nn.Sequential(\n","            nn.Linear(metadata_input_features, 128),\n","            nn.BatchNorm1d(128),\n","            Swish_Module(), #ReLU\n","            nn.Dropout(0.3),\n","            nn.Linear(128, 256),\n","            nn.BatchNorm1d(256),\n","            Swish_Module(), #ReLU\n","            nn.Dropout(0.3),\n","            nn.Linear(256, metadata_output_features),\n","            nn.BatchNorm1d(metadata_output_features),\n","            Swish_Module() #ReLU\n","        )\n","\n","        # Combine features from image model and metadata\n","        combined_features = self.image_out_features + metadata_output_features\n","        self.final_fc = nn.Sequential(\n","            nn.Linear(combined_features, 512),\n","            nn.BatchNorm1d(512),\n","            Swish_Module(), #ReLU\n","            nn.Dropout(0.5),\n","            nn.Linear(512, num_classes),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, image, metadata):\n","        image_features = self.image_model(image)\n","        metadata_features = self.metadata_fc(metadata)\n","        combined_features = torch.cat((image_features, metadata_features), dim=1)\n","        output = self.final_fc(combined_features)\n","        \n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["# Data Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T13:26:52.931940Z","iopub.status.busy":"2024-09-01T13:26:52.931591Z","iopub.status.idle":"2024-09-01T13:26:52.937505Z","shell.execute_reply":"2024-09-01T13:26:52.936502Z","shell.execute_reply.started":"2024-09-01T13:26:52.931913Z"},"trusted":true},"outputs":[],"source":["# Define image transformer\n","data_transforms = {\n","    'valid': A.Compose([\n","        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n","        A.Normalize(\n","            mean=[0.4815, 0.4578, 0.4082], \n","            std=[0.2686, 0.2613, 0.2758],\n","            max_pixel_value=255.0),\n","        ToTensorV2(),\n","    ])\n","}"]},{"cell_type":"markdown","metadata":{},"source":["# Inference Function"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def inference(df_test, file_test_hdf, test_loader, model, device):\n","    model.eval();\n","    \n","    preds = []\n","    with torch.no_grad():\n","        bar = tqdm(enumerate(test_loader), total=len(test_loader))\n","        for step, data in bar:        \n","            images = data['image'].to(device, dtype=torch.float)\n","            metadata = data['metadata'].to(device, dtype=torch.float)\n","            batch_size = images.size(0)\n","            outputs = model(images, metadata).squeeze()\n","            preds.append(outputs.detach().cpu().numpy())\n","            \n","    preds = np.concatenate(preds).flatten()\n","    \n","    return preds"]},{"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Prepare test loader            \n","test_dataset = ISICDataset(df, num_feat, TEST_HDF, data_transforms['valid'])\n","test_loader = DataLoader(test_dataset, batch_size=CONFIG['valid_batch_size'], \n","                          num_workers=2, shuffle=False, pin_memory=True)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# model load\n","model = CustomISICModel(CONFIG['model_name'], pretrained=True)\n","model_dict = model.state_dict()\n","\n","# pre-trained metadata model load\n","meta_state_dict = torch.load(\"/kaggle/input/isic-2024-pytorch-training-baseline-vit/AUROC0.5185_Loss0.3199_epoch31.bin\")\n","meta_pretrained_dict = {k: v for k, v in meta_state_dict.items() if k in model_dict}\n","model_dict.update(meta_pretrained_dict)\n","\n","#pre-trained swin image model load\n","image_state_dict = torch.load(\"/kaggle/input/isic-2024-swin-model-ver-24/AUROC0.5012_Loss0.2076_epoch50.bin\")\n","image_pretrained_dict = {k: v for k, v in image_state_dict.items() if k in model_dict}\n","model_dict.update(image_pretrained_dict) \n","\n","model.to(CONFIG['device'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["preds = inference(df, TEST_HDF, test_loader, model, CONFIG['device'])\n","df_sub[\"target\"] = preds"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_sub"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_sub[['isic_id', 'target']].to_csv(\"submission.csv\", index=False)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":9094797,"sourceId":63056,"sourceType":"competition"},{"datasetId":5615162,"sourceId":9277641,"sourceType":"datasetVersion"},{"sourceId":193670944,"sourceType":"kernelVersion"},{"sourceId":194572299,"sourceType":"kernelVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
