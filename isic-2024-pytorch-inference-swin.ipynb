{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":9277641,"sourceType":"datasetVersion","datasetId":5615162},{"sourceId":193670944,"sourceType":"kernelVersion"},{"sourceId":194572299,"sourceType":"kernelVersion"}],"dockerImageVersionId":30747,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ISIC 2024 - Skin Cancer Detection: Pytorch Model w/ Image + Metadata Inference","metadata":{}},{"cell_type":"markdown","source":"Inspired by [motono0223](https://www.kaggle.com/code/motono0223/isic-pytorch-baseline-pseudo-labeling-eva02#Create-Model) and [Jiadi Wang](https://www.kaggle.com/code/hugowjd/isic-2024-pytorch-inference-effnet-b3#Create-Model)\n\nIdea:\n* Feature engineer and append snippet of data to images\n* Data augment images for diversity\n* Inference with multiple folds\n\nNotebooks:\n* [Training notebook](https://www.kaggle.com/code/qiaoyingzhang/isic-2024-pytorch-training-baseline-swin/notebook?scriptVersionId=191356799) -- version 16\n* Inference notebook (current)\n\nBest models (manually selected from training notebook) are uploaded in [dataset](https://www.kaggle.com/datasets/qiaoyingzhang/isic-2024-swin-pytorch-best-models)\n* Fold 0 best model from [version 9](https://www.kaggle.com/code/qiaoyingzhang/isic-2024-pytorch-training-baseline-swin?scriptVersionId=191338975) (AUROC0.5181_Loss0.2202_epoch41_fold0.bin)\n* Fold 1 best model from [version 8](https://www.kaggle.com/code/qiaoyingzhang/isic-2024-pytorch-training-baseline-swin?scriptVersionId=191338963) (AUROC0.5184_Loss0.3117_epoch31_fold1.bin)\n* Fold 2 best model from [version 10](https://www.kaggle.com/code/qiaoyingzhang/isic-2024-pytorch-training-baseline-swin?scriptVersionId=191342208) (AUROC0.5173_Loss0.2800_epoch41_fold2.bin)\n* Fold 3 best model from [version 11](https://www.kaggle.com/code/qiaoyingzhang/isic-2024-pytorch-training-baseline-swin?scriptVersionId=191342225) (AUROC0.5175_Loss0.3176_epoch6_fold3.bin)\n* Fold 4 best model from [version 12](https://www.kaggle.com/code/qiaoyingzhang/isic-2024-pytorch-training-baseline-swin?scriptVersionId=191346483) (AUROC0.5177_Loss0.2280_epoch49_fold4.bin)","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport copy\nimport time\nimport random\nimport glob\nimport h5py\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nfrom io import BytesIO\n\n# PyTorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\n# Utils\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Sklearn Imports\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import StratifiedGroupKFold\n\n# For Image Models\nimport timm\n\n# Albumentations for augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-01T13:26:38.516199Z","iopub.execute_input":"2024-09-01T13:26:38.516478Z","iopub.status.idle":"2024-09-01T13:26:46.683475Z","shell.execute_reply.started":"2024-09-01T13:26:38.516454Z","shell.execute_reply":"2024-09-01T13:26:46.682675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initialize Environment & Configuration","metadata":{}},{"cell_type":"code","source":"CONFIG = {\n    \"seed\": 2024,\n    \"img_size\": 224,\n    \"model_name\": 'swin_large_patch4_window7_224',\n    \"valid_batch_size\": 64,\n    \"multiple_folds\": True,\n    \"selected\": True,\n    \"n_fold\": 5,\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n}\n\n# Set seed for reproducibility\ndef seed_everything(seed):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nseed_everything(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2024-09-01T13:26:46.684886Z","iopub.execute_input":"2024-09-01T13:26:46.685368Z","iopub.status.idle":"2024-09-01T13:26:46.723215Z","shell.execute_reply.started":"2024-09-01T13:26:46.685343Z","shell.execute_reply":"2024-09-01T13:26:46.722538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = \"/kaggle/input/isic-2024-challenge\"\nTEST_CSV = f'{ROOT_DIR}/test-metadata.csv'\nTEST_HDF = f'{ROOT_DIR}/test-image.hdf5'\nSAMPLE = f'{ROOT_DIR}/sample_submission.csv'","metadata":{"execution":{"iopub.status.busy":"2024-09-01T13:26:46.724458Z","iopub.execute_input":"2024-09-01T13:26:46.724733Z","iopub.status.idle":"2024-09-01T13:26:46.734792Z","shell.execute_reply.started":"2024-09-01T13:26:46.724710Z","shell.execute_reply":"2024-09-01T13:26:46.734072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Setup (Psuedo Labeling)","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(TEST_CSV)\ndf['target'] = 0 # dummy","metadata":{"execution":{"iopub.status.busy":"2024-09-01T13:20:34.530460Z","iopub.execute_input":"2024-09-01T13:20:34.530729Z","iopub.status.idle":"2024-09-01T13:20:34.558654Z","shell.execute_reply.started":"2024-09-01T13:20:34.530707Z","shell.execute_reply":"2024-09-01T13:20:34.557791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature engineering\ndf['lesion_size_ratio'] = df['tbp_lv_minorAxisMM'] / df['clin_size_long_diam_mm']\ndf['color_uniformity'] = df['tbp_lv_color_std_mean'] / df['tbp_lv_radial_color_std_max']\ndf['3d_position_distance'] = np.sqrt(df['tbp_lv_x'] ** 2 + df['tbp_lv_y'] ** 2 + df['tbp_lv_z'] ** 2) \n# List of numerical features to be scaled\nnum_feat = ['age_approx', 'lesion_size_ratio', 'color_uniformity', \n            'tbp_lv_Lext', 'tbp_lv_eccentricity', '3d_position_distance']\n\n# Replace infinite values with NaN\ndf[num_feat] = df[num_feat].replace([np.inf, -np.inf], np.nan)\n\n# Handle missing values (if any) by filling them with the mean of the column\ndf[num_feat] = df[num_feat].fillna(df[num_feat].mean())\n\n# Scale numerical features\nscaler = StandardScaler()\ndf[num_feat] = scaler.fit_transform(df[num_feat])\n\nprint(\"Feature engineering and scaling complete.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sanity check\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample submission\ndf_sub = pd.read_csv(SAMPLE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Manipulation","metadata":{}},{"cell_type":"code","source":"# Dataset\nclass ISICDataset(Dataset):\n    def __init__(self, dataframe, feat, file_path, transforms=None):\n        self.df = dataframe\n        self.file_path = h5py.File(file_path, mode=\"r\")\n        self.transforms = transforms\n        self.metadata = self.df[feat].values\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        target = row['target']\n        isic_id = row['isic_id']\n        \n        metadata = self.metadata[idx]\n\n        image = np.array(Image.open(BytesIO(self.file_path[isic_id][()])))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transforms:\n            image = self.transforms(image=image)[\"image\"]\n        \n        return {'image': image, 'target': target, 'metadata': metadata}","metadata":{"execution":{"iopub.status.busy":"2024-09-01T13:26:46.736852Z","iopub.execute_input":"2024-09-01T13:26:46.737684Z","iopub.status.idle":"2024-09-01T13:26:46.748320Z","shell.execute_reply.started":"2024-09-01T13:26:46.737627Z","shell.execute_reply":"2024-09-01T13:26:46.747440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"class Swish(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, i):\n        result = i * nn.Sigmoid()(i)\n        ctx.save_for_backward(i)\n        return result\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_variables[0]\n        sigmoid_i = nn.Sigmoid()(i)\n        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n\nclass Swish_Module(nn.Module):\n    def forward(self, x):\n        return Swish.apply(x)\n        \n\nclass CustomISICModel(nn.Module):\n    def __init__(self, model_name, num_classes=1, pretrained=True, checkpoint_path=None):\n        super(CustomISICModel, self).__init__()\n        self.image_model = timm.create_model(model_name, pretrained=pretrained, \n                                             chekpoint_path=checkpoint_path)\n        self.image_out_features = self.image_model.get_classifier().in_features\n        self.image_model.reset_classifier(0)  # Remove the original classifier\\\n        \n\n        # Metadata part\n        metadata_input_features = 6\n        metadata_output_features = 128\n\n        self.metadata_fc = nn.Sequential(\n            nn.Linear(metadata_input_features, 128),\n            nn.BatchNorm1d(128),\n            Swish_Module(), #ReLU\n            nn.Dropout(0.3),\n            nn.Linear(128, 256),\n            nn.BatchNorm1d(256),\n            Swish_Module(), #ReLU\n            nn.Dropout(0.3),\n            nn.Linear(256, metadata_output_features),\n            nn.BatchNorm1d(metadata_output_features),\n            Swish_Module() #ReLU\n        )\n\n        # Combine features from image model and metadata\n        combined_features = self.image_out_features + metadata_output_features\n        self.final_fc = nn.Sequential(\n            nn.Linear(combined_features, 512),\n            nn.BatchNorm1d(512),\n            Swish_Module(), #ReLU\n            nn.Dropout(0.5),\n            nn.Linear(512, num_classes),\n            nn.Sigmoid()\n        )\n\n    def forward(self, image, metadata):\n        image_features = self.image_model(image)\n        metadata_features = self.metadata_fc(metadata)\n        combined_features = torch.cat((image_features, metadata_features), dim=1)\n        output = self.final_fc(combined_features)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-09-01T13:26:47.439816Z","iopub.execute_input":"2024-09-01T13:26:47.440155Z","iopub.status.idle":"2024-09-01T13:26:47.453117Z","shell.execute_reply.started":"2024-09-01T13:26:47.440130Z","shell.execute_reply":"2024-09-01T13:26:47.452055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"# Define image transformer\ndata_transforms = {\n    'valid': A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.Normalize(\n            mean=[0.4815, 0.4578, 0.4082], \n            std=[0.2686, 0.2613, 0.2758],\n            max_pixel_value=255.0),\n        ToTensorV2(),\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-01T13:26:52.931591Z","iopub.execute_input":"2024-09-01T13:26:52.931940Z","iopub.status.idle":"2024-09-01T13:26:52.937505Z","shell.execute_reply.started":"2024-09-01T13:26:52.931913Z","shell.execute_reply":"2024-09-01T13:26:52.936502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference Function","metadata":{}},{"cell_type":"code","source":"def inference(df_test, file_test_hdf, test_loader, model, device):\n    model.eval();\n    \n    preds = []\n    with torch.no_grad():\n        bar = tqdm(enumerate(test_loader), total=len(test_loader))\n        for step, data in bar:        \n            images = data['image'].to(device, dtype=torch.float)\n            metadata = data['metadata'].to(device, dtype=torch.float)\n            batch_size = images.size(0)\n            outputs = model(images, metadata).squeeze()\n            preds.append(outputs.detach().cpu().numpy())\n            \n    preds = np.concatenate(preds).flatten()\n    \n    return preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# Prepare test loader            \ntest_dataset = ISICDataset(df, num_feat, TEST_HDF, data_transforms['valid'])\ntest_loader = DataLoader(test_dataset, batch_size=CONFIG['valid_batch_size'], \n                          num_workers=2, shuffle=False, pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model load\nmodel = CustomISICModel(CONFIG['model_name'], pretrained=True)\nmodel_dict = model.state_dict()\n\n# pre-trained metadata model load\nmeta_state_dict = torch.load(\"/kaggle/input/isic-2024-pytorch-training-baseline-vit/AUROC0.5185_Loss0.3199_epoch31.bin\")\nmeta_pretrained_dict = {k: v for k, v in meta_state_dict.items() if k in model_dict}\nmodel_dict.update(meta_pretrained_dict)\n\n#pre-trained swin image model load\nimage_state_dict = torch.load(\"/kaggle/input/isic-2024-swin-model-ver-24/AUROC0.5012_Loss0.2076_epoch50.bin\")\nimage_pretrained_dict = {k: v for k, v in image_state_dict.items() if k in model_dict}\nmodel_dict.update(image_pretrained_dict) \n\nmodel.to(CONFIG['device'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = inference(df, TEST_HDF, test_loader, model, CONFIG['device'])\ndf_sub[\"target\"] = preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub[['isic_id', 'target']].to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}